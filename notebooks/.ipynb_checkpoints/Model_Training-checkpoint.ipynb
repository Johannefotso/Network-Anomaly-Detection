{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johan\\AppData\\Local\\Temp\\ipykernel_16656\\2959336945.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV data into the pandas dataframe\n",
    "file = 'C:\\\\Users\\\\johan\\\\OneDrive\\\\Documents\\\\Work\\\\Network-Anomaly-Detection\\\\.venv\\\\data\\\\data.csv'\n",
    "data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johan\\AppData\\Local\\Temp\\ipykernel_16656\\1288935411.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[\"label\"].replace(['normal'], 0, inplace=True)\n",
      "C:\\Users\\johan\\AppData\\Local\\Temp\\ipykernel_16656\\1288935411.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[\"label\"].replace(LABELS, 1 , inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Let's replace the label column values to 0 for normal and 1 for others!\n",
    "\n",
    "LABELS = data[\"label\"].unique() # Get Unique Values of label column\n",
    "LABELS = [label for label in LABELS if label != \"normal\"] #All labels other than Normal!\n",
    "\n",
    "data[\"label\"].replace(['normal'], 0, inplace=True)\n",
    "data[\"label\"].replace(LABELS, 1 , inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(\"None\") # fill all the empty hosts with 0\n",
    "\n",
    "#Now let's encode all the columns which are not float or int e.g. sourceIP, MAC to make it possible for model to interpret\n",
    "columnsToEncode = list(data.select_dtypes(include=['category', 'object']))  \n",
    "            \n",
    "le = LabelEncoder() # use label encoder from sklearn\n",
    "\n",
    "for feature in columnsToEncode:\n",
    "    try:\n",
    "        data[feature] = le.fit_transform(data[feature])\n",
    "        #print(data[feature])\n",
    "    except:\n",
    "        print ('error' + feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>uid</th>\n",
       "      <th>sourceMac</th>\n",
       "      <th>sourceIp</th>\n",
       "      <th>destIp</th>\n",
       "      <th>destMac</th>\n",
       "      <th>sourcePort</th>\n",
       "      <th>destPort</th>\n",
       "      <th>host</th>\n",
       "      <th>kIn</th>\n",
       "      <th>...</th>\n",
       "      <th>outPacketsNo</th>\n",
       "      <th>protocol</th>\n",
       "      <th>urgent</th>\n",
       "      <th>ack</th>\n",
       "      <th>push</th>\n",
       "      <th>reset</th>\n",
       "      <th>syn</th>\n",
       "      <th>fin</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>19357</td>\n",
       "      <td>8000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>1939</td>\n",
       "      <td>8000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>19668</td>\n",
       "      <td>8000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>19807</td>\n",
       "      <td>8000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>19851</td>\n",
       "      <td>8000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  uid  sourceMac  sourceIp  destIp  destMac  sourcePort  \\\n",
       "0           0    0          0         2      15        5       19357   \n",
       "1           1    0          0         2      15        5        1939   \n",
       "2           2    0          0         2      15        5       19668   \n",
       "3           3    0          0         2      15        5       19807   \n",
       "4           4    0          0         2      15        5       19851   \n",
       "\n",
       "   destPort  host  kIn  ...  outPacketsNo  protocol  urgent  ack  push  reset  \\\n",
       "0      8000     3    0  ...             2        17       0    0     0      0   \n",
       "1      8000     3    0  ...             2        17       0    0     0      0   \n",
       "2      8000     3    0  ...             1        17       0    0     0      0   \n",
       "3      8000     3    0  ...             1        17       0    0     0      0   \n",
       "4      8000     3    0  ...             1        17       0    0     0      0   \n",
       "\n",
       "   syn  fin  timestamp  label  \n",
       "0    0    0      22374      1  \n",
       "1    0    0      22374      1  \n",
       "2    0    0      22374      1  \n",
       "3    0    0      22374      1  \n",
       "4    0    0      22374      1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=5, test_size=0.9 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Train, Val \u001b[38;5;241m=\u001b[39m \u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_selection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\johan\\OneDrive\\Documents\\Work\\Network-Anomaly-Detection\\.venv\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\johan\\OneDrive\\Documents\\Work\\Network-Anomaly-Detection\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2660\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2662\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\johan\\OneDrive\\Documents\\Work\\Network-Anomaly-Detection\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2308\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2305\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2312\u001b[0m     )\n\u001b[0;32m   2314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=5, test_size=0.9 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "Train, Val = sklearn.model_selection.train_test_split(data, test_size=0.9, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    298792\n",
       "0      9197\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2689714\n",
       "0      82189\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Val[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.0\n"
     ]
    }
   ],
   "source": [
    "Attack = Train[Train['label']==1]\n",
    "Normal = Train[Train['label']==0]\n",
    "outlier_fraction = np.ceil(len(Attack)/float(len(Normal)))\n",
    "\n",
    "#Let's print how many more outliers are there in the dataset compared to normal data\n",
    "print(outlier_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307989, 20)\n",
      "(307989,)\n"
     ]
    }
   ],
   "source": [
    "#Let's now split the features and the target ground truth\n",
    "features = [feature for feature in Train.columns.tolist() if feature not in [\"label\"]]\n",
    "target = \"label\"\n",
    "\n",
    "# Define a random state \n",
    "state = np.random.RandomState(42)\n",
    "X_train = Train[features]\n",
    "Y_train = Train[target]\n",
    "\n",
    "X_val = Val[features]\n",
    "Y_val = Val[target]\n",
    "\n",
    "X_outliers = state.uniform(low=0, high=1, size=(X_train.shape[0], X_train.shape[1]))\n",
    "# Print the shapes of X & Y\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's initalize some classifiers\n",
    "classifiers = {\n",
    "    \"Isolation Forest\":IsolationForest(n_estimators=100, max_samples=len(X_train), \n",
    "                                       contamination=outlier_fraction,random_state=state, verbose=1),\n",
    "    \"Local Outlier Factor\":LocalOutlierFactor(n_neighbors=20, algorithm='auto', \n",
    "                                              leaf_size=30, metric='minkowski',\n",
    "                                              p=2, metric_params=None, contamination=0.03),\n",
    "    \"Support Vector Machine\":OneClassSVM(kernel='rbf', degree=3, gamma=0.1,nu=0.05, \n",
    "                                         max_iter=-1 )\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Outlier Factor: 291532\n",
      "Accuracy Score :\n",
      "0.053433726529194224\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.89      0.05      9197\n",
      "           1       0.89      0.03      0.05    298792\n",
      "\n",
      "    accuracy                           0.05    307989\n",
      "   macro avg       0.46      0.46      0.05    307989\n",
      "weighted avg       0.87      0.05      0.05    307989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_outliers = len(Attack)\n",
    "for i, (clf_name,clf) in enumerate(classifiers.items()):\n",
    "    #Fit the data and tag outliers\n",
    "    if clf_name == \"Local Outlier Factor\":\n",
    "        continue\n",
    "        y_pred = clf.fit_predict(X_train)\n",
    "        scores_prediction = clf.negative_outlier_factor_\n",
    "    elif clf_name == \"Support Vector Machine\":\n",
    "        clf.fit(X_train)\n",
    "        y_pred = clf.predict(X_train)\n",
    "    else:    \n",
    "        continue\n",
    "        clf.fit(X_train)\n",
    "        scores_prediction = clf.decision_function(X_train)\n",
    "        y_pred = clf.predict(X_train)\n",
    "        \n",
    "    #Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\n",
    "    y_pred[y_pred == 1] = 0\n",
    "    y_pred[y_pred == -1] = 1\n",
    "    n_errors = (y_pred != Y_train).sum()\n",
    "    # Run Classification Metrics\n",
    "    print(\"{}: {}\".format(clf_name,n_errors))\n",
    "    print(\"Accuracy Score :\")\n",
    "    print(accuracy_score(Y_train,y_pred))\n",
    "    print(\"Classification Report :\")\n",
    "    print(classification_report(Y_train,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_outliers = len(Attack)\n",
    "for i, (clf_name,clf) in enumerate(classifiers.items()):\n",
    "    #Fit the data and tag outliers\n",
    "    if clf_name == \"Local Outlier Factor\":\n",
    "        continue\n",
    "        y_pred = clf.fit_predict(X_train)\n",
    "        scores_prediction = clf.negative_outlier_factor_\n",
    "    elif clf_name == \"Support Vector Machine\":\n",
    "        clf.fit(X_train)\n",
    "        y_pred = clf.predict(X_train)\n",
    "    else:    \n",
    "        continue\n",
    "        clf.fit(X_train)\n",
    "        scores_prediction = clf.decision_function(X_train)\n",
    "        y_pred = clf.predict(X_train)\n",
    "        \n",
    "    #Reshape the prediction values to 0 for Valid transactions , 1 for Fraud transactions\n",
    "    y_pred[y_pred == 1] = 0\n",
    "    y_pred[y_pred == -1] = 1\n",
    "    n_errors = (y_pred != Y_train).sum()\n",
    "    # Run Classification Metrics\n",
    "    print(\"{}: {}\".format(clf_name,n_errors))\n",
    "    print(\"Accuracy Score :\")\n",
    "    print(accuracy_score(Y_train,y_pred))\n",
    "    print(\"Classification Report :\")\n",
    "    print(classification_report(Y_train,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt-SNE visualization of test data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 24\u001b[0m tsne_plot(\u001b[43mX_train\u001b[49m[:\u001b[38;5;241m8000\u001b[39m], Y_train[:\u001b[38;5;241m8000\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "def tsne_plot(x1, y1, name=\"graph.png\"):\n",
    "    \n",
    "    #Scale features to improve the training ability of TSNE.\n",
    "    standard_scaler = StandardScaler()\n",
    "    df2_std = standard_scaler.fit_transform(x1)\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    x_test_2d = tsne.fit_transform(df2_std)\n",
    "    \n",
    "    #Build the scatter plot with the two types of transactions.\n",
    "    color_map = {0:'green', 1:'red'}\n",
    "    plt.figure()\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x = x_test_2d[y1==cl,0], \n",
    "                    y = x_test_2d[y1==cl,1], \n",
    "                    c = color_map[idx], \n",
    "                    label = cl)\n",
    "    plt.xlabel('X in t-SNE')\n",
    "    plt.ylabel('Y in t-SNE')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title('t-SNE visualization of test data')\n",
    "    plt.show()\n",
    "    \n",
    "tsne_plot(X_train[:8000], Y_train[:8000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I think training this kind of dataset with autoencoders makes more sense so let's try that\n",
    "\n",
    "## input layer \n",
    "input_layer = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "## encoding part\n",
    "encoded = Dense(100, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoded = Dense(50, activation='relu')(encoded)\n",
    "\n",
    "## decoding part\n",
    "decoded = Dense(50, activation='tanh')(encoded)\n",
    "decoded = Dense(100, activation='tanh')(decoded)\n",
    "\n",
    "## output layer\n",
    "output_layer = Dense(X_train.shape[1], activation='relu')(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the mdoel\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "autoencoder.compile(optimizer=\"adadelta\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's do bit of data transformation for scaling\n",
    "\n",
    "x = X_train\n",
    "y = Y_train\n",
    "\n",
    "x_scale = preprocessing.MinMaxScaler().fit_transform(x.values)\n",
    "x_norm, x_fraud = x_scale[y == 0], x_scale[y == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.1274 - val_loss: 0.1273\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.1270 - val_loss: 0.1269\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1266 - val_loss: 0.1264\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1261 - val_loss: 0.1259\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1255 - val_loss: 0.1253\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.1249 - val_loss: 0.1247\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1243 - val_loss: 0.1240\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.1236 - val_loss: 0.1234\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1230 - val_loss: 0.1228\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.1223 - val_loss: 0.1221\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.1216 - val_loss: 0.1214\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1209 - val_loss: 0.1207\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1202 - val_loss: 0.1199\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1195 - val_loss: 0.1192\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.1188 - val_loss: 0.1185\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.1180 - val_loss: 0.1178\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1173 - val_loss: 0.1171\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.1166 - val_loss: 0.1164\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1159 - val_loss: 0.1157\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1152 - val_loss: 0.1150\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.1144 - val_loss: 0.1142\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.1137 - val_loss: 0.1135\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1130 - val_loss: 0.1128\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.1123 - val_loss: 0.1122\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1116 - val_loss: 0.1115\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1109 - val_loss: 0.1108\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1102 - val_loss: 0.1101\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.1096 - val_loss: 0.1094\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.1089 - val_loss: 0.1087\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1082 - val_loss: 0.1081\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1075 - val_loss: 0.1074\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.1069 - val_loss: 0.1068\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.1062 - val_loss: 0.1061\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1056 - val_loss: 0.1055\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.1049 - val_loss: 0.1048\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.1043 - val_loss: 0.1042\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.1036 - val_loss: 0.1036\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1030 - val_loss: 0.1029\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1024 - val_loss: 0.1023\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1017 - val_loss: 0.1017\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1011 - val_loss: 0.1011\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.1005 - val_loss: 0.1004\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.0999 - val_loss: 0.0998\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0992 - val_loss: 0.0992\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0986 - val_loss: 0.0986\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0980 - val_loss: 0.0980\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0974 - val_loss: 0.0974\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.0968 - val_loss: 0.0968\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.0962 - val_loss: 0.0962\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.0956 - val_loss: 0.0956\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(x_norm[0:8000], x_norm[0:8000], \n",
    "                batch_size = 256, epochs = 50, \n",
    "                shuffle = True, validation_split = 0.20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try to get latent learnt representation by autoencoder\n",
    "hidden_representation = Sequential()\n",
    "hidden_representation.add(autoencoder.layers[0])\n",
    "hidden_representation.add(autoencoder.layers[1])\n",
    "hidden_representation.add(autoencoder.layers[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_hid_rep = hidden_representation.predict(x_norm[9000:12000])\n",
    "fraud_hid_rep = hidden_representation.predict(x_fraud[9000:12000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's try to visualize TSNE again for the learnt representation\n",
    "rep_x = np.append(norm_hid_rep, fraud_hid_rep, axis = 0)\n",
    "y_n = np.zeros(norm_hid_rep.shape[0])\n",
    "y_f = np.ones(fraud_hid_rep.shape[0])\n",
    "rep_y = np.append(y_n, y_f)\n",
    "\n",
    "tsne_plot(rep_x, rep_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99       783\n",
      "         1.0       0.99      1.00      0.99       717\n",
      "\n",
      "    accuracy                           0.99      1500\n",
      "   macro avg       0.99      0.99      0.99      1500\n",
      "weighted avg       0.99      0.99      0.99      1500\n",
      "\n",
      "\n",
      "Accuracy Score:  0.9946666666666667\n"
     ]
    }
   ],
   "source": [
    "#Finally we can train a classifier on learnt representations\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(rep_x, rep_y, test_size=0.25)\n",
    "clf = LogisticRegression(solver=\"lbfgs\").fit(train_x, train_y)\n",
    "pred_y = clf.predict(val_x)\n",
    "\n",
    "print (\"\")\n",
    "print (\"Classification Report: \")\n",
    "print (classification_report(val_y, pred_y))\n",
    "\n",
    "print (\"\")\n",
    "print (\"Accuracy Score: \", accuracy_score(val_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coding/MyProjects/Avira-AnomalyDetection/env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     82189\n",
      "           1       1.00      1.00      1.00   2689714\n",
      "\n",
      "    accuracy                           1.00   2771903\n",
      "   macro avg       1.00      0.99      1.00   2771903\n",
      "weighted avg       1.00      1.00      1.00   2771903\n",
      "\n",
      "\n",
      "Accuracy Score:  0.9996976806186941\n"
     ]
    }
   ],
   "source": [
    "#Finally we can train a classifier on learnt representations\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(rep_x, rep_y, test_size=0.25)\n",
    "clf = LogisticRegression(solver=\"lbfgs\").fit(X_train, Y_train)\n",
    "pred_y = clf.predict(X_val)\n",
    "\n",
    "print (\"\")\n",
    "print (\"Classification Report: \")\n",
    "print (classification_report(Y_val, pred_y))\n",
    "\n",
    "print (\"\")\n",
    "print (\"Accuracy Score: \", accuracy_score(Y_val, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
